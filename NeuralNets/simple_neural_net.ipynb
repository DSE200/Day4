{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Networks with PyTorch\n",
    "\n",
    "In this assignment, you'll build your first neural network using **PyTorch**.\n",
    "\n",
    "## What is a Neural Network?\n",
    "A neural network is like stacking simple functions (layers) to learn complex patterns:\n",
    "- **Input Layer**: Takes your features\n",
    "- **Hidden Layers**: Process and transform data\n",
    "- **Output Layer**: Makes predictions\n",
    "\n",
    "## Why PyTorch?\n",
    "- **Simple and Pythonic**: Feels like writing regular Python\n",
    "- **Industry standard**: Used by researchers and companies\n",
    "- **Flexible**: Easy to debug and customize\n",
    "\n",
    "## Learning Objectives\n",
    "- Build a simple neural network\n",
    "- Understand layers, neurons, and activation functions\n",
    "- Train and evaluate the model\n",
    "- Visualize training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch scikit-learn matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scale the Data (IMPORTANT for Neural Networks!)\n",
    "\n",
    "**TODO:** Use `StandardScaler` to normalize the features.\n",
    "\n",
    "**Hints:**\n",
    "- Create a `StandardScaler()` object\n",
    "- Use `.fit_transform()` on training data\n",
    "- Use `.transform()` on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create scaler and scale data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print(\"Data scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert to PyTorch Tensors\n",
    "\n",
    "PyTorch works with tensors (like numpy arrays but on GPU).\n",
    "\n",
    "**TODO:** Convert data to PyTorch tensors.\n",
    "\n",
    "**Hints:**\n",
    "- Use `torch.FloatTensor()` for features\n",
    "- Use `torch.FloatTensor()` for labels (reshape to (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert to tensors\n",
    "# X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "# y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "# X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "# y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "# print(f\"Tensor shapes: {X_train_tensor.shape}, {y_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Neural Network\n",
    "\n",
    "### Task: Create a neural network class\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (30 features)\n",
    "  ↓\n",
    "Dense Layer (16 neurons, ReLU)\n",
    "  ↓\n",
    "Dense Layer (8 neurons, ReLU)\n",
    "  ↓\n",
    "Output Layer (1 neuron, Sigmoid)\n",
    "```\n",
    "\n",
    "**Key Concepts:**\n",
    "- **nn.Module**: Base class for all neural networks\n",
    "- **nn.Linear**: Fully connected layer\n",
    "- **nn.ReLU**: ReLU activation\n",
    "- **nn.Sigmoid**: Sigmoid activation\n",
    "\n",
    "**TODO:** Complete the neural network class.\n",
    "\n",
    "**Hints:**\n",
    "1. Inherit from `nn.Module`\n",
    "2. Define layers in `__init__`\n",
    "3. Define forward pass in `forward` method\n",
    "4. Use `nn.Linear(input_size, output_size)` for layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define neural network class\n",
    "# class SimpleNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleNet, self).__init__()\n",
    "#         # TODO: Define layers\n",
    "#         # self.fc1 = nn.Linear(30, 16)\n",
    "#         # self.fc2 = nn.Linear(16, 8)\n",
    "#         # self.fc3 = nn.Linear(8, 1)\n",
    "#         # self.relu = nn.ReLU()\n",
    "#         # self.sigmoid = nn.Sigmoid()\n",
    "#     \n",
    "#     def forward(self, x):\n",
    "#         # TODO: Define forward pass\n",
    "#         # x = self.relu(self.fc1(x))\n",
    "#         # x = self.relu(self.fc2(x))\n",
    "#         # x = self.sigmoid(self.fc3(x))\n",
    "#         # return x\n",
    "#         pass\n",
    "\n",
    "# TODO: Create model instance\n",
    "# model = SimpleNet()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Loss Function and Optimizer\n",
    "\n",
    "**TODO:** Set up loss function and optimizer.\n",
    "\n",
    "**Hints:**\n",
    "- Loss: `nn.BCELoss()` for binary classification\n",
    "- Optimizer: `optim.Adam(model.parameters(), lr=0.001)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define loss and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(\"Loss and optimizer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "### Task: Write training loop\n",
    "\n",
    "**Training Steps (for each epoch):**\n",
    "1. Forward pass: `outputs = model(X_train_tensor)`\n",
    "2. Calculate loss: `loss = criterion(outputs, y_train_tensor)`\n",
    "3. Backward pass: `loss.backward()`\n",
    "4. Update weights: `optimizer.step()`\n",
    "5. Zero gradients: `optimizer.zero_grad()`\n",
    "\n",
    "**TODO:** Complete the training loop.\n",
    "\n",
    "**Hints:**\n",
    "- Train for 100 epochs\n",
    "- Store loss history for plotting\n",
    "- Print progress every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training loop\n",
    "# epochs = 100\n",
    "# losses = []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     # Forward pass\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = criterion(outputs, y_train_tensor)\n",
    "#     \n",
    "#     # Backward pass\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     \n",
    "#     # Store loss\n",
    "#     losses.append(loss.item())\n",
    "#     \n",
    "#     # Print progress\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress\n",
    "\n",
    "**TODO:** Plot the training loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot loss curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(losses, linewidth=2)\n",
    "# plt.xlabel('Epoch', fontsize=12)\n",
    "# plt.ylabel('Loss', fontsize=12)\n",
    "# plt.title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set\n",
    "\n",
    "**TODO:** Make predictions and evaluate.\n",
    "\n",
    "**Hints:**\n",
    "- Use `model.eval()` for evaluation mode\n",
    "- Use `with torch.no_grad()` to disable gradients\n",
    "- Convert predictions to numpy for sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_pred_proba = model(X_test_tensor)\n",
    "#     y_pred = (y_pred_proba > 0.5).float()\n",
    "\n",
    "# TODO: Convert to numpy\n",
    "# y_pred_np = y_pred.numpy().flatten()\n",
    "# y_test_np = y_test.values\n",
    "\n",
    "# TODO: Calculate metrics\n",
    "# accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "\n",
    "# TODO: Print results\n",
    "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test_np, y_pred_np, target_names=['Malignant', 'Benign']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare with Traditional ML\n",
    "\n",
    "**TODO:** Train a Random Forest and compare.\n",
    "\n",
    "**Hints:**\n",
    "- Import and train `RandomForestClassifier`\n",
    "- Compare accuracy and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# rf.fit(X_train_scaled, y_train)\n",
    "# rf_pred = rf.predict(X_test_scaled)\n",
    "# rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# TODO: Compare\n",
    "# print(f\"PyTorch Neural Network: {accuracy:.4f}\")\n",
    "# print(f\"Random Forest: {rf_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
