{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML with FLAML\n",
    "\n",
    "In this assignment, you'll learn how to use **FLAML** (Fast Lightweight AutoML) for automated machine learning.\n",
    "\n",
    "## What is AutoML?\n",
    "AutoML automates the process of:\n",
    "- **Model Selection**: Tries different algorithms (XGBoost, LightGBM, Random Forest, etc.)\n",
    "- **Hyperparameter Tuning**: Finds best parameters for each model\n",
    "- **Feature Engineering**: Creates and selects useful features\n",
    "- **Model Comparison**: Identifies the best performing model\n",
    "\n",
    "## Why FLAML?\n",
    "- **Fast**: Efficient search algorithms\n",
    "- **Simple**: Easy API, minimal code\n",
    "- **Smart**: Uses cost-effective hyperparameter optimization\n",
    "- **Interpretable**: Provides feature importance and model insights\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand how AutoML works\n",
    "- Use FLAML to automatically find the best model\n",
    "- Interpret feature importance\n",
    "- Compare AutoML results with manual approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T08:36:21.423396Z",
     "start_time": "2025-11-07T08:36:18.726906Z"
    }
   },
   "source": "!%pip install flaml scikit-learn matplotlib seaborn pandas numpy xgboost lightgbm shap",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml in /usr/local/lib/python3.11/site-packages (2.3.6)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.5.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.9.2)\r\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (1.24.3)\r\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/site-packages (4.6.0)\r\n",
      "Collecting shap\r\n",
      "  Downloading shap-0.49.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.54.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ekirimlioglu/Library/Python/3.11/lib/python/site-packages (from matplotlib) (24.1)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ekirimlioglu/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/site-packages (from shap) (4.67.0)\r\n",
      "Collecting slicer==0.0.8 (from shap)\r\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/site-packages (from shap) (0.61.2)\r\n",
      "Collecting cloudpickle (from shap)\r\n",
      "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/ekirimlioglu/Library/Python/3.11/lib/python/site-packages (from shap) (4.12.2)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/site-packages (from numba>=0.54->shap) (0.44.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/ekirimlioglu/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Downloading shap-0.49.1-cp311-cp311-macosx_10_9_x86_64.whl (558 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m558.7/558.7 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\r\n",
      "Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)\r\n",
      "Installing collected packages: slicer, cloudpickle, shap\r\n",
      "Successfully installed cloudpickle-3.1.2 shap-0.49.1 slicer-0.0.8\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nfrom flaml import AutoML\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {data.DESCR.split('**')[1].strip()}\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create and Configure AutoML\n",
    "\n",
    "### Task: Set up FLAML AutoML\n",
    "\n",
    "**Key Parameters:**\n",
    "- `task`: Type of ML task ('classification' or 'regression')\n",
    "- `time_budget`: Maximum time in seconds for searching (60-300 for this exercise)\n",
    "- `metric`: Metric to optimize ('accuracy', 'roc_auc', 'f1', etc.)\n",
    "- `estimator_list`: Which models to try (default: tries multiple algorithms)\n",
    "- `log_file_name`: Where to save search logs\n",
    "- `seed`: Random seed for reproducibility\n",
    "\n",
    "**Available Estimators in FLAML:**\n",
    "- `'lgbm'`: LightGBM\n",
    "- `'xgboost'`: XGBoost\n",
    "- `'rf'`: Random Forest\n",
    "- `'extra_tree'`: Extra Trees\n",
    "- `'lrl1'`: Logistic Regression with L1 regularization\n",
    "- `'lrl2'`: Logistic Regression with L2 regularization\n",
    "\n",
    "**Hints:**\n",
    "1. Create an `AutoML()` object\n",
    "2. Use `fit()` method with X_train, y_train\n",
    "3. Set task='classification'\n",
    "4. Set a time_budget (start with 60 seconds)\n",
    "5. Set metric='accuracy'\n",
    "\n",
    "**TODO:** Complete the AutoML setup and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create AutoML instance\n",
    "# automl = AutoML()\n",
    "\n",
    "# TODO: Configure and train\n",
    "# automl.fit(\n",
    "#     X_train, y_train,\n",
    "#     task='classification',\n",
    "#     time_budget=60,\n",
    "#     metric='accuracy',\n",
    "#     log_file_name='automl_log.txt',\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# print(\"AutoML training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine AutoML Results\n",
    "\n",
    "### Task: Explore what AutoML discovered\n",
    "\n",
    "**Useful Attributes:**\n",
    "- `automl.best_estimator`: Name of the best model found\n",
    "- `automl.best_config`: Best hyperparameters\n",
    "- `automl.best_loss`: Best validation loss\n",
    "- `automl.model`: The trained model object\n",
    "\n",
    "**TODO:** Print information about the best model found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print best estimator name\n",
    "# print(f\"Best estimator: {automl.best_estimator}\")\n",
    "\n",
    "# TODO: Print best configuration\n",
    "# print(f\"\\nBest configuration:\")\n",
    "# for param, value in automl.best_config.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "\n",
    "# TODO: Print best validation accuracy\n",
    "# print(f\"\\nBest validation accuracy: {1 - automl.best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Test Set\n",
    "\n",
    "### Task: Make predictions and evaluate performance\n",
    "\n",
    "**Hints:**\n",
    "- Use `automl.predict()` for class predictions\n",
    "- Use `automl.predict_proba()` for probability predictions\n",
    "- Calculate accuracy, ROC AUC, and generate classification report\n",
    "\n",
    "**TODO:** Evaluate the AutoML model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions\n",
    "# y_pred = automl.predict(X_test)\n",
    "# y_pred_proba = automl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# TODO: Calculate metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# TODO: Print results\n",
    "# print(f\"\\nTest Set Performance:\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "# print(f\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SHAP Feature Importance\n",
    "\n",
    "### Task: Use SHAP to explain model predictions\n",
    "\n",
    "**What is SHAP?**\n",
    "SHAP (SHapley Additive exPlanations) shows:\n",
    "- Which features contribute most to predictions\n",
    "- Direction of impact (positive/negative)\n",
    "- Per-sample explanations (not just global)\n",
    "\n",
    "**TODO:** Create SHAP visualizations.\n",
    "\n",
    "**Hints:**\n",
    "1. Create `shap.TreeExplainer(automl.model.estimator)` for tree models\n",
    "2. Calculate SHAP values with `explainer.shap_values(X_test)`\n",
    "3. Use `shap.summary_plot()` for beeswarm plot - GOLD!\n",
    "4. Try `shap.waterfall_plot()` for single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create SHAP explainer for tree-based models\n",
    "# if automl.best_estimator in ['lgbm', 'xgboost', 'rf', 'extra_tree']:\n",
    "#     explainer = shap.TreeExplainer(automl.model.estimator)\n",
    "#     \n",
    "#     # TODO: Calculate SHAP values for test set\n",
    "#     shap_values = explainer.shap_values(X_test)\n",
    "#     \n",
    "#     # TODO: Summary plot (beeswarm)\n",
    "#     # Shows feature importance + direction + distribution\n",
    "#     shap.summary_plot(shap_values, X_test, plot_type=\"dot\")\n",
    "#     \n",
    "#     # TODO: Bar plot - Simple feature importance\n",
    "#     shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "#     \n",
    "#     # TODO: Waterfall plot for single prediction\n",
    "#     # Shows how each feature contributes to one specific prediction\n",
    "#     shap.waterfall_plot(shap.Explanation(values=shap_values[0], \n",
    "#                                           base_values=explainer.expected_value, \n",
    "#                                           data=X_test.iloc[0],\n",
    "#                                           feature_names=X_test.columns))\n",
    "# else:\n",
    "#     print(\"SHAP TreeExplainer only works with tree-based models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare AutoML with Specific Estimators\n",
    "\n",
    "### Task: Run AutoML with only specific estimators\n",
    "\n",
    "**TODO:** Try AutoML with only tree-based models vs only linear models.\n",
    "\n",
    "**Hints:**\n",
    "- Use `estimator_list` parameter\n",
    "- Tree-based: `['lgbm', 'xgboost', 'rf']`\n",
    "- Linear: `['lrl1', 'lrl2']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run with tree-based models only\n",
    "# automl_tree = AutoML()\n",
    "# automl_tree.fit(\n",
    "#     X_train, y_train,\n",
    "#     task='classification',\n",
    "#     time_budget=60,\n",
    "#     metric='accuracy',\n",
    "#     estimator_list=['lgbm', 'xgboost', 'rf'],\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# TODO: Run with linear models only\n",
    "# automl_linear = AutoML()\n",
    "# automl_linear.fit(\n",
    "#     X_train, y_train,\n",
    "#     task='classification',\n",
    "#     time_budget=60,\n",
    "#     metric='accuracy',\n",
    "#     estimator_list=['lrl1', 'lrl2'],\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# TODO: Compare results\n",
    "# print(f\"Tree-based best: {automl_tree.best_estimator} - Accuracy: {accuracy_score(y_test, automl_tree.predict(X_test)):.4f}\")\n",
    "# print(f\"Linear best: {automl_linear.best_estimator} - Accuracy: {accuracy_score(y_test, automl_linear.predict(X_test)):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
